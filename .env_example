FLASH_API_KEY=API_KEY_FLASH
FLASH_MODEL=gemini/gemini-2.0-flash

# PRO_API_KEY=API_KEY_PRO
# PRO_MODEL=gemini/gemini-2.5-pro

EVALUATION_API_KEY=API_KEY_EVAL
EVALUATION_MODEL=gpt-4o

# These are optional
# FLASH_BASE_URL=http://localhost:11434
# PRO_BASE_URL=your_pro_base_url_if_needed # Commented out as PRO_MODEL is removed
# EVALUATION_BASE_URL=http://localhost:11434

# --- LiteLLM Configuration ---
# Default model string for litellm (e.g., "gpt-3.5-turbo", "ollama/mistral", "claude-3-haiku-20240307")
# See litellm documentation for more model strings: https://docs.litellm.ai/docs/providers
LITELLM_DEFAULT_MODEL="gemini/gemini-2.0-flash-lite"
GEMINI_API_KEY=""

# For Google Cloud services (Vertex AI, AI Studio) using Application Default Credentials (ADC)
# with a service account key, set the path to your JSON key file.
# This is often used in conjunction with models like "vertex_ai/gemini-1.5-pro-preview-0409".
# GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/service-account-key.json"

# API keys for models accessed via litellm should generally be set as environment variables
# that litellm recognizes (e.g., OPENAI_API_KEY, COHERE_API_KEY, ANTHROPIC_API_KEY, GOOGLE_API_KEY).
# litellm will automatically pick these up. Refer to litellm documentation for specific provider needs.
# Example:
# OPENAI_API_KEY=your_openai_api_key
# AZURE_API_KEY=your_azure_api_key # (for Azure OpenAI, also need other AZURE_* vars)

# LITELLM_MAX_TOKENS=4096
# LITELLM_TEMPERATURE=1.0
# LITELLM_TOP_P=0.9
# LITELLM_TOP_K=40
